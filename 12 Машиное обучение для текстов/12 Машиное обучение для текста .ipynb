{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выявление токсичные комментарии\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучаем модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройм модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "### Инструкция по выполнению проекта\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Чтение данных\n",
    "df =  pd.read_csv(r'\\Users\\Asus\\Documents\\Python Scripts\\Яндекс практикум\\Машиное обучение для текстов\\toxictweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Проверка информаций данных\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic ratio comments 10.17%\n"
     ]
    }
   ],
   "source": [
    "# Загляним на порцентное соотношение токсичних коментарий\n",
    "toxic_ratio = pd.Series(df['toxic']==1).sum()/df.shape[0]\n",
    "\n",
    "print('toxic ratio comments {:.2%}'.format(toxic_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import string\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "# Определенте стоп слов\n",
    "stop_words = set(nltk_stopwords.words('english'))\n",
    "\n",
    "#Определение стоварь Знаков препинания \n",
    "punctuation = string.punctuation \n",
    "\n",
    "#Определение функций ламматизатора\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функцция лемматизаций\n",
    "def tokenizer(text):\n",
    "    #Определение слова токенов\n",
    "    tokens = [ word for sent in sent_tokenize(text) for word in word_tokenize(sent)]\n",
    "    tokens = list(filter(lambda t: t not in punctuation, tokens)) # Уборка знаков припенания внутри слов\n",
    "    tokens = list(filter(lambda t: t.lower() not in stop_words, tokens)) #Уборка стоа-слов\n",
    "    filtered_tokens = []\n",
    "    for token in tokens: # Регулярные выражений\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    filtered_tokens = list(\n",
    "        map(lambda token: wordnet_lemmatizer.lemmatize(token.lower()), filtered_tokens)) #Лемматизаци токенов\n",
    "    filtered_tokens = list(filter(lambda t: t not in punctuation, filtered_tokens)) # Фильтр пл знаков припенания\n",
    "    return ' '.join(filtered_tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['text_clean'] = df['text'].map(tokenizer) #Применение лематизацик тексту\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Определяем функцию для того чтобы разделить датасет на : обущающий, валидацилный и тестовый\n",
    "\n",
    "def train_test_valid_split(dataframe, test_size, validate_size):\n",
    "    # Делим на обучующую и тестовую часть\n",
    "    df_train, df_test = train_test_split(\n",
    "        dataframe,\n",
    "        test_size=test_size,\n",
    "        shuffle = False,\n",
    "        \n",
    "    )\n",
    "    # Воторой раз делим датасет\n",
    "    post_split_validate_size = validate_size / (1 - test_size)\n",
    "    df_train, df_validate = train_test_split(\n",
    "        df_train,\n",
    "        test_size=post_split_validate_size,\n",
    "        shuffle =False ,\n",
    "        \n",
    "    )\n",
    "    return df_train, df_test, df_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111698, 3) (15958, 3) (31915, 3)\n"
     ]
    }
   ],
   "source": [
    "#Деление датасета на трайн, валид и тест\n",
    "df_train, df_test, df_validate = train_test_valid_split(df, 0.1, 0.2)\n",
    "\n",
    "print(df_train.shape,\n",
    "     df_test.shape, \n",
    "     df_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww match background colour 'm seemingly stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man 'm really trying edit war 's guy const...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ca n't make real suggestion improvement wonder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page 's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                          text_clean  \n",
       "0  explanation edits made username hardcore metal...  \n",
       "1  d'aww match background colour 'm seemingly stu...  \n",
       "2  hey man 'm really trying edit war 's guy const...  \n",
       "3  ca n't make real suggestion improvement wonder...  \n",
       "4                   sir hero chance remember page 's  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "При подготовке данных перед обучением моделей , при использование tag_pos время исполнения лематизаций свыше 30 мин. Для оптимизаций алгоритма лучше результат получился с применением map. В среднем 10% от коментарий являются токсичными. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "train_corpus = df_train['text_clean'].values.astype('U')\n",
    "# Определение стоп-слова\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "# Определение TF-IDF для обучения моделей как признаки\n",
    "tfidf_train = count_tf_idf.fit_transform(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение таргета для обучения моделей\n",
    "train_labels = df_train['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression() # Обучение модели логистической  регрессий с дкфолтными параметрами\n",
    "model.fit(tfidf_train, train_labels)\n",
    " \n",
    "validate_labels = df_validate['toxic']\n",
    "validate_corpus = df_validate['text_clean'].values.astype('U')\n",
    "tfidf_validate = count_tf_idf.transform(validate_corpus)\n",
    " \n",
    "pred_validate = model.predict(tfidf_validate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7296268088347296"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_LR = f1_score(validate_labels ,  pred_validate)\n",
    "\n",
    "f1_LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "Модель LinearRegression без тюнинга параметров f1 полчилось 0,73, близко к заданому 0,75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.03 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\"({'penalty': 'l1'}, {'max_iter': 2})\": 0.7538864628820962,\n",
       " \"({'penalty': 'l1'}, {'max_iter': 5})\": 0.7780734433209153,\n",
       " \"({'penalty': 'l1'}, {'max_iter': 100})\": 0.7778566359119944,\n",
       " \"({'penalty': 'l2'}, {'max_iter': 2})\": 0.0,\n",
       " \"({'penalty': 'l2'}, {'max_iter': 5})\": 0.577391304347826,\n",
       " \"({'penalty': 'l2'}, {'max_iter': 100})\": 0.7296268088347296}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from itertools import product\n",
    "\n",
    "# подбор параметров для RandomForestRegressor  и вывод RMSE на тестовый датасет \n",
    "buf_2 = dict()\n",
    "for i in product([{'penalty':'l1'},{'penalty':'l2'}],\n",
    "              [{'max_iter':2},{ 'max_iter':5}, {'max_iter':100}]\n",
    "              ):\n",
    "    rfr = LogisticRegression(random_state = 123,**i[0],**i[1])\n",
    "    rfr.fit(tfidf_train, train_labels)\n",
    "    pred_2 = rfr.predict(tfidf_validate)\n",
    "    buf_2[str(i)] = f1_score(validate_labels,pred_2)\n",
    "buf_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\"({'criterion': 'gini'}, {'max_depth': 5})\": 0.5072926162260711,\n",
       " \"({'criterion': 'gini'}, {'max_depth': 10})\": 0.5875682486350272,\n",
       " \"({'criterion': 'gini'}, {'max_depth': 100})\": 0.7164230438521065,\n",
       " \"({'criterion': 'entropy'}, {'max_depth': 5})\": 0.506721348826612,\n",
       " \"({'criterion': 'entropy'}, {'max_depth': 10})\": 0.5786587937579081,\n",
       " \"({'criterion': 'entropy'}, {'max_depth': 100})\": 0.6877615938389419}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# подбор параметров для RandomForestRegressor  и вывод f1 на тестовый датасет \n",
    "buf = dict()\n",
    "for i in product([{'criterion':'gini'},{'criterion':'entropy'}],\n",
    "              [{'max_depth':5},{ 'max_depth':10}, {'max_depth':100}]\n",
    "              ):\n",
    "    dtc = DecisionTreeClassifier(random_state = 123,**i[0],**i[1])\n",
    "    dtc.fit(tfidf_train, train_labels)\n",
    "    pred_3 = dtc.predict(tfidf_validate)\n",
    "    buf[str(i)] = f1_score(validate_labels,pred_3)\n",
    "buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.23 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\"({'C': 0.1}, {'max_iter': 5})\": 0.7530020321448365,\n",
       " \"({'C': 0.1}, {'max_iter': 10})\": 0.7340182648401826,\n",
       " \"({'C': 0.1}, {'max_iter': 100})\": 0.7343601445141662,\n",
       " \"({'C': 1.0}, {'max_iter': 5})\": 0.7932324711241256,\n",
       " \"({'C': 1.0}, {'max_iter': 10})\": 0.7823969385980171,\n",
       " \"({'C': 1.0}, {'max_iter': 100})\": 0.7834693523181108,\n",
       " \"({'C': 2.5}, {'max_iter': 5})\": 0.7861707357037522,\n",
       " \"({'C': 2.5}, {'max_iter': 10})\": 0.7804149377593361,\n",
       " \"({'C': 2.5}, {'max_iter': 100})\": 0.7784004075394803}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# подбор параметров для RandomForestRegressor  и вывод f1 на тестовый датасет \n",
    "buf_s= dict()\n",
    "for i in product([{'C':0.1},{'C':1.0} ,{'C':2.5}],\n",
    "              [{'max_iter':5},{ 'max_iter':10}, {'max_iter':100}]\n",
    "              ):\n",
    "    svc = LinearSVC(random_state = 123,**i[0],**i[1])\n",
    "    svc.fit(tfidf_train, train_labels)\n",
    "    pred_3 = svc.predict(tfidf_validate)\n",
    "    buf_s[str(i)] = f1_score(validate_labels,pred_3)\n",
    "buf_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"({'criterion': 'gini'}, {'max_depth': 100})\", 0.7164230438521065),\n",
       " (\"({'penalty': 'l1'}, {'max_iter': 5})\", 0.7780734433209153),\n",
       " (\"({'C': 1.0}, {'max_iter': 5})\", 0.7932324711241256)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Поиск найлучше рузкльтата по RMSE для кажлой модели \n",
    "best_result = []\n",
    "for buffer in (buf, buf_2, buf_s):\n",
    "    param = max(buffer.items(), key=lambda x: x[1]) \n",
    "    best_result.append(param)\n",
    "\n",
    "best_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7871794871794872"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = df_test['toxic'] # Определение таргетов для теста\n",
    "test_corpus = df_test['text_clean'].values.astype('U') # Определение признаком для теста\n",
    "\n",
    "tfidf_test = count_tf_idf.transform(test_corpus) \n",
    "\n",
    "best_model = LinearSVC(random_state = 123 ,  max_iter= 5) # Модель с лучшими параметрами на валид\n",
    "\n",
    "best_model.fit(tfidf_train, train_labels) # Обучение лучше модель\n",
    "pred_test = best_model.predict(tfidf_test) # Предсказание на тестовой выборке\n",
    "\n",
    "\n",
    "f1_best = f1_score(test_labels ,  pred_test) # Метрика F1 на тестовой выборке\n",
    "\n",
    "f1_best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод \n",
    "\n",
    "Лучше значение метррики F1 проучается при модели LogisticRegression с параметрами 'penalty'= 'l1' и 'max_iter'= 5, что выше заданому по заданию"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
